# ğŸ§ª CÃ³mo Ejecutar Tests de Rendimiento Reales

## ğŸ“‹ Resumen RÃ¡pido

```bash
# 1. Instalar dependencias (si no estÃ¡n instaladas)
pip install -r requirements.txt

# 2. Descargar modelos (REQUIERE INTERNET)
python3 download_models.py

# 3. Ejecutar tests reales
python3 test_real_performance.py
```

---

## ğŸ¯ Tests Disponibles

### 1. `test_setup_and_config.py` - VerificaciÃ³n de ConfiguraciÃ³n
**No requiere modelos descargados** âœ…

```bash
python3 test_setup_and_config.py
```

**QuÃ© hace:**
- âœ… Verifica que todas las dependencias estÃ©n instaladas
- âœ… Detecta si los modelos estÃ¡n en cache
- âœ… Mide el overhead del sistema (VAD, conversiÃ³n, etc.)
- âœ… Proporciona instrucciones de descarga

**Salida esperada:**
```
âœ… Todas las dependencias estÃ¡n instaladas correctamente
ğŸ“Š Overhead del Sistema: ~0.2ms (MÃNIMO)
âš ï¸ Modelos no disponibles en cache
```

---

### 2. `download_models.py` - Descarga de Modelos
**REQUIERE INTERNET** ğŸŒ

```bash
python3 download_models.py
```

**QuÃ© hace:**
- ğŸ“¥ Descarga Qwen 0.5B Q4_K_M (~300MB)
- ğŸ“¥ Descarga Whisper tiny.en (~75MB)
- ğŸ’¾ Guarda en cache de HuggingFace

**Tiempo estimado:**
- Con internet rÃ¡pido: 1-3 minutos
- Con internet normal: 3-10 minutos
- Con internet lento: 10-20 minutos

**DÃ³nde se guardan:**
```
~/.cache/huggingface/hub/
â”œâ”€â”€ models--Qwen--Qwen2.5-0.5B-Instruct-GGUF/
â””â”€â”€ models--Systran--faster-whisper-tiny.en/
```

---

### 3. `test_real_performance.py` - Tests de Velocidad Real
**REQUIERE MODELOS DESCARGADOS** ğŸ“¦

```bash
python3 test_real_performance.py
```

**QuÃ© hace:**
- ğŸ§ª Test 1: LLM (Qwen 0.5B)
  - Carga el modelo desde cache
  - Genera 3 respuestas de prueba
  - Mide latencia promedio, mÃ­nima y mÃ¡xima
  
- ğŸ§ª Test 2: ASR (Whisper tiny.en)
  - Carga el modelo desde cache
  - Transcribe 4 chunks de audio sintÃ©tico
  - Mide RTF (Real-Time Factor)
  - Calcula latencias
  
- ğŸ§ª Test 3: Pipeline Completo
  - Simula conversaciÃ³n real
  - Audio â†’ ASR â†’ LLM
  - Mide tiempo total del pipeline

**Salida esperada:**
```
âœ… LLM (Qwen 0.5B):
   â€¢ Descarga: 2.5s (desde cache)
   â€¢ Latencia promedio: 350ms

âœ… ASR (Whisper tiny.en):
   â€¢ Descarga: 1.8s (desde cache)
   â€¢ RTF: 0.18x
   â€¢ Latencia promedio: 180ms

âœ… Pipeline Completo:
   â€¢ Tiempo total: 530ms
   â€¢ RTF: 0.21x
```

---

## ğŸš« Limitaciones en CI/CD

### Â¿Por quÃ© no funcionan en GitHub Actions?

GitHub Actions **no tiene acceso a internet externo** para descargar desde HuggingFace.

**Error tÃ­pico:**
```
âŒ Error: [Errno -5] No address associated with hostname
```

### Soluciones:

#### OpciÃ³n 1: Ejecutar Localmente (Recomendado) âœ…
```bash
# En tu mÃ¡quina local con internet:
git clone <repo>
cd copiloto-conversacional-ingles-fluido
pip install -r requirements.txt
python3 download_models.py
python3 test_real_performance.py
```

#### OpciÃ³n 2: Docker con Modelos Pre-descargados
```dockerfile
FROM python:3.12

# Instalar dependencias
COPY requirements.txt .
RUN pip install -r requirements.txt

# Descargar modelos durante build
RUN python3 download_models.py

# Copiar cÃ³digo
COPY . /app
WORKDIR /app

# Ejecutar tests
CMD ["python3", "test_real_performance.py"]
```

#### OpciÃ³n 3: GitHub Actions con Cache
```yaml
- name: Cache models
  uses: actions/cache@v3
  with:
    path: ~/.cache/huggingface
    key: models-${{ runner.os }}

- name: Download models (if not cached)
  run: python3 download_models.py

- name: Run performance tests
  run: python3 test_real_performance.py
```

---

## ğŸ“Š Resultados Esperados

### ASR (Whisper tiny.en + int8)
```
RTF (Real-Time Factor): 0.10-0.25x
Latencia: 100-250ms por segundo de audio
Estado: ğŸš€ EXCELENTE
```

**InterpretaciÃ³n:**
- RTF 0.20x significa que 1 segundo de audio se procesa en 200ms
- RTF < 1.0 = Viable para tiempo real
- RTF < 0.5 = Excelente para tiempo real
- RTF < 0.3 = Ã“ptimo

### LLM (Qwen 0.5B Q4_K_M)
```
Latencia: 200-500ms por generaciÃ³n
Tokens: ~40-60 tokens por generaciÃ³n
Estado: âœ… BUENO
```

### Pipeline Completo (ASR + LLM)
```
Tiempo total: 300-750ms
RTF: 0.15-0.40x
Estado: âœ… BUENO para conversaciÃ³n en tiempo real
```

---

## ğŸ” Verificar Modelos Descargados

```bash
# Ver modelos en cache
ls -lh ~/.cache/huggingface/hub/

# Ver tamaÃ±o total
du -sh ~/.cache/huggingface/hub/

# Limpiar cache (si necesitas espacio)
rm -rf ~/.cache/huggingface/hub/
```

---

## â“ FAQ

### Â¿Necesito GPU?
**No**. El sistema estÃ¡ optimizado para CPU:
- ASR: tiny.en es suficientemente rÃ¡pido en CPU
- LLM: Qwen 0.5B Q4_K_M estÃ¡ cuantizado para CPU

Con GPU serÃ­a 5-10x mÃ¡s rÃ¡pido, pero no es necesario.

### Â¿CuÃ¡nto espacio ocupan los modelos?
```
LLM (Qwen 0.5B Q4_K_M): ~300MB
ASR (Whisper tiny.en): ~75MB
Total: ~375MB
```

### Â¿Los modelos se descargan cada vez?
**No**. Se descargan **solo la primera vez**. DespuÃ©s se usan desde cache.

### Â¿Puedo usar otros modelos?
SÃ­, pero los benchmarks cambiarÃ¡n:
- `base.en` es mÃ¡s lento (RTF ~0.5x)
- `small.en` es muy lento (RTF ~1.0x)
- `tiny.en` es el mÃ¡s rÃ¡pido para tiempo real

### Â¿Funciona offline despuÃ©s de descargar?
**SÃ­**. Una vez descargados, los modelos estÃ¡n en cache y funcionan offline.

---

## ğŸ“ Entender los Resultados

### RTF (Real-Time Factor)
```
RTF = Tiempo de procesamiento / DuraciÃ³n del audio

Ejemplo:
  Audio: 1.0 segundo
  Procesamiento: 0.2 segundos
  RTF = 0.2 / 1.0 = 0.2x

âœ… RTF < 1.0 â†’ MÃ¡s rÃ¡pido que tiempo real
âŒ RTF > 1.0 â†’ MÃ¡s lento que tiempo real
```

### Latencia
```
Tiempo desde que llega el audio hasta que sale la respuesta

Para conversaciÃ³n natural:
  â€¢ < 500ms â†’ Excelente
  â€¢ < 1000ms â†’ Bueno
  â€¢ < 2000ms â†’ Aceptable
  â€¢ > 2000ms â†’ Lento
```

---

## ğŸ“š Documentos Relacionados

- `ANALISIS_VELOCIDAD_ASR.md` - AnÃ¡lisis tÃ©cnico completo
- `TESTS_REALES_EXPLICACION.md` - ExplicaciÃ³n detallada
- `RESUMEN_EJECUTIVO.md` - Resumen ejecutivo
- `verify_asr_config.py` - VerificaciÃ³n de optimizaciones

---

## âœ… Checklist para Tests Reales

- [ ] Instalar dependencias: `pip install -r requirements.txt`
- [ ] Verificar instalaciÃ³n: `python3 test_setup_and_config.py`
- [ ] Tener internet disponible
- [ ] Descargar modelos: `python3 download_models.py`
- [ ] Ejecutar tests: `python3 test_real_performance.py`
- [ ] Revisar resultados
- [ ] Comparar con benchmarks teÃ³ricos

---

*Ãšltima actualizaciÃ³n*: 2026-02-03  
*Estado*: âœ… Scripts listos para ejecutar  
*Requisito*: Internet para primera descarga
