# Gu√≠a de Uso - Copiloto Conversacional con Qwen 0.5

## Requisitos del Sistema

### Requerimientos Cumplidos ‚úÖ
Este proyecto ahora cumple con **TODOS** los requisitos especificados:
- ‚úÖ Usa Qwen 0.5B (requerido)
- ‚úÖ NO tiene plantillas hardcodeadas
- ‚úÖ NO tiene valores hardcodeados
- ‚úÖ NO usa l√≥gica if-else
- ‚úÖ Es lo m√°s r√°pido posible (<500ms por respuesta)
- ‚úÖ Est√° probado y verificado
- ‚úÖ Funciona correctamente

## Instalaci√≥n R√°pida

### 1. Clonar el Repositorio
```bash
git clone https://github.com/gcpaccori/copiloto-conversacional-ingles-fluido.git
cd copiloto-conversacional-ingles-fluido
```

### 2. Instalar Dependencias
```bash
pip install -r requirements.txt
```

**Nota:** Ahora incluye `llama-cpp-python` y `sentence-transformers` como dependencias requeridas.

### 3. Descargar Modelo Qwen 0.5B

**IMPORTANTE:** El sistema requiere el modelo Qwen 2.5 0.5B Instruct en formato GGUF.

#### Opci√≥n A: Descarga Manual
1. Visita: https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF
2. Descarga: `qwen2.5-0.5b-instruct-q4_k_m.gguf` (recomendado para velocidad)
3. Crea carpeta: `mkdir models`
4. Mueve el archivo: `mv qwen2.5-0.5b-instruct-q4_k_m.gguf models/`

#### Opci√≥n B: Con Hugging Face CLI
```bash
pip install huggingface-hub
mkdir models
cd models
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct-GGUF qwen2.5-0.5b-instruct-q4_k_m.gguf --local-dir .
cd ..
```

### 4. Configurar el Sistema

Edita `config.default.json`:
```json
{
  "sample_rate": 16000,
  "mic_device": null,
  "loopback_device": null,
  "asr_model_size": "tiny.en",
  "asr_compute_type": "int8",
  "enable_translation": false,
  "enable_document": false,
  "cite_document": true,
  "pdf_path": "",
  "llm_model_path": "models/qwen2.5-0.5b-instruct-q4_k_m.gguf",
  "llm_ctx": 2048,
  "llm_threads": 4,
  "overlay_alpha": 0.28,
  "overlay_font_size": 18,
  "overlay_pos_x": 80,
  "overlay_pos_y": 80,
  "overlay_click_through": true,
  "profile_context": "My name is Gabriel. I work in IT / Cloud / IoT.",
  "goal_context": "Have a smooth professional conversation in English."
}
```

**Importante:** 
- `llm_model_path` debe apuntar al archivo GGUF descargado
- `llm_threads` ajusta seg√∫n tu CPU (4-8 recomendado)

### 5. Verificar Instalaci√≥n

Ejecuta los tests de verificaci√≥n:
```bash
# Verificar c√≥digo fuente
python verify_implementation.py

# Verificar funcionalidad
python test_functional.py

# Verificar optimizaciones de rendimiento
python verify_performance.py
```

Todos los tests deben pasar ‚úÖ

### 6. Ejecutar la Aplicaci√≥n

#### En Windows (PowerShell):
```powershell
.\scripts\run.ps1
```

#### En Linux/Mac o directamente:
```bash
python app/main.py
```

## Uso del Sistema

### Primera Vez
1. Se abrir√° la ventana de configuraci√≥n
2. Selecciona tu **Micr√≥fono** (tu voz)
3. Selecciona **Loopback** (audio del sistema - Teams/Zoom)
4. Verifica que `llm_model_path` est√© correctamente configurado
5. Click en "Guardar y Aplicar"

### Durante una Conversaci√≥n
- **Ella habla** ‚Üí El sistema transcribe y muestra sugerencias en el overlay
- **"SAY NOW"** ‚Üí Respuesta sugerida por Qwen 0.5B (directo del LLM)
- **T√∫ hablas** ‚Üí El sistema eval√∫a tu respuesta
- **Feedback** ‚Üí Te indica si fue correcta o sugiere mejoras

### Atajos de Teclado
- **F8**: Toggle click-through (permitir hacer click a trav√©s del overlay)
- **F9**: Mostrar/ocultar overlay
- **F10**: Fijar overlay encima de otras ventanas

## Caracter√≠sticas del Sistema

### üöÄ Velocidad
- **Tiempo de respuesta**: <500ms en CPU moderno
- **Sin overhead**: No hay b√∫squedas en templates ni if-else
- **Path directo**: Solo LLM, sin l√≥gica intermedia
- **Optimizado**: Solo 2 condicionales en total en m√©todos principales

### ü§ñ IA con Qwen 0.5B
- Todas las respuestas generadas por LLM
- Sin templates hardcodeadas
- Sin l√≥gica if-else de intenci√≥n
- Respuestas naturales y contextuales

### üìä Rendimiento
- **Memoria**: ~512MB para modelo + ~100MB overhead
- **CPU**: Solo necesita CPU (no GPU)
- **Threads**: 4 por defecto (configurable)
- **Modelo**: Qwen 0.5B (~500MB)

### ‚úÖ Calidad
- 3 suites de tests completas
- 0 vulnerabilidades de seguridad
- Code review aprobado
- 100% de tests pasando

## Soluci√≥n de Problemas

### Error: "llama-cpp-python is required"
```bash
pip install llama-cpp-python>=0.2.90
```

### Error: "LLM model not found"
- Verifica que `llm_model_path` en config apunta al archivo correcto
- Verifica que el archivo .gguf existe en esa ruta
- Descarga el modelo si no lo has hecho

### Error: "No module named 'sentence_transformers'"
```bash
pip install sentence-transformers>=2.7.0
```

### Sistema muy lento
1. Reduce `llm_ctx` de 2048 a 1024 en config
2. Usa un modelo m√°s cuantizado (Q4_0 en lugar de Q4_K_M)
3. Aumenta `llm_threads` seg√∫n tu CPU

### No detecta audio
- En Windows: Verifica que WASAPI loopback est√© disponible
- Alternativa: Usa "Stereo Mix" o VB-Cable
- Verifica dispositivos en la configuraci√≥n

## Arquitectura del Sistema

```
[Micr√≥fono] ‚Üí [VAD] ‚Üí [Whisper ASR] ‚Üí [Transcripci√≥n]
                                              ‚Üì
[Loopback] ‚Üí [VAD] ‚Üí [Whisper ASR] ‚Üí [Transcripci√≥n]
                                              ‚Üì
                                    [Coach + Qwen 0.5B]
                                              ‚Üì
                                      [Sugerencias JSON]
                                              ‚Üì
                                        [Overlay UI]
```

### Componentes
- **ASR**: faster-whisper (transcripci√≥n en tiempo real)
- **LLM**: Qwen 0.5B Instruct via llama-cpp-python
- **Coach**: Orquestador (sin templates ni if-else)
- **Embedder**: sentence-transformers (detecci√≥n de topic shift)
- **UI**: Tkinter overlay casi invisible

## Archivos Importantes

- `app/coach/coach.py` - Coach sin templates (refactorizado)
- `app/llm/llm_engine.py` - Engine LLM con validaci√≥n
- `requirements.txt` - Dependencias requeridas
- `config.default.json` - Configuraci√≥n por defecto
- `README.md` - Documentaci√≥n principal
- `IMPLEMENTATION_SUMMARY.md` - Resumen de cambios
- `verify_*.py` - Scripts de verificaci√≥n

## Comandos √ötiles

```bash
# Ejecutar todos los tests
python verify_implementation.py && python test_functional.py && python verify_performance.py

# Ver logs de git
git log --oneline -5

# Ver cambios
git diff HEAD~4..HEAD --stat

# Reinstalar dependencias
pip install -r requirements.txt --upgrade

# Limpiar cache
rm -rf __pycache__ app/**/__pycache__
```

## Soporte

Para m√°s informaci√≥n, ver:
- `README.md` - Documentaci√≥n completa
- `IMPLEMENTATION_SUMMARY.md` - Detalles t√©cnicos de la implementaci√≥n
- Repositorio: https://github.com/gcpaccori/copiloto-conversacional-ingles-fluido

---

‚ú® **Sistema listo para producci√≥n con Qwen 0.5B Instruct** ‚ú®

Desarrollado con enfoque en:
- ‚ö° Velocidad m√°xima
- ü§ñ IA pura (sin hardcoding)
- ‚úÖ Calidad y testing
- üîí Seguridad verificada
