# Resultados de Rendimiento

Mediciones reales del sistema con modelos descargados desde HuggingFace.

## üñ•Ô∏è Hardware de Prueba

**CPU**: AMD EPYC 7763 64-Core Processor  
**Cores Utilizados**: 4 cores  
**RAM**: 16 GB  
**GPU**: Ninguna (solo CPU)  
**Sistema Operativo**: Linux (Ubuntu)

## üìä Resultados de Performance

### Test 1: ASR (Whisper tiny.en)

**Modelo**: `Systran/faster-whisper-tiny.en`  
**Configuraci√≥n**: INT8, beam_size=1, optimizado para velocidad

```
‚Ä¢ Chunks procesados: 4
‚Ä¢ Audio total: 5.30s
‚Ä¢ Tiempo de procesamiento: 1.26s
‚Ä¢ Latencia promedio: 316ms
‚Ä¢ Latencia m√≠nima: 306ms
‚Ä¢ Latencia m√°xima: 333ms
‚Ä¢ RTF (Real-Time Factor): 0.24x
```

**Estado**: üöÄ **EXCELENTE** (RTF < 0.3)

**Interpretaci√≥n**: El sistema procesa 1 segundo de audio en solo 0.24 segundos, lo que significa que es **4 veces m√°s r√°pido** que el tiempo real.

### Test 2: LLM (Qwen 0.5B Q4_K_M)

**Modelo**: `Qwen/Qwen2.5-0.5B-Instruct-GGUF`  
**Archivo**: `qwen2.5-0.5b-instruct-q4_k_m.gguf` (491 MB)  
**Configuraci√≥n**: Q4_K_M quantization, CPU inference

```
‚Ä¢ Prompts probados: 3
‚Ä¢ Latencia promedio: 294ms
‚Ä¢ Latencia m√≠nima: 259ms
‚Ä¢ Latencia m√°xima: 326ms
```

**Estado**: üöÄ **EXCELENTE** (<500ms)

**Ejemplo de respuesta**:
```
Input: She said: 'What did she say?'
Output: What did she say?
Latencia: 326ms
```

### Test 3: Pipeline Completo (ASR ‚Üí LLM)

Simulaci√≥n de conversaci√≥n real con procesamiento completo.

```
‚Ä¢ Duraci√≥n del audio: 2.50s
‚Ä¢ Tiempo ASR: 317ms
‚Ä¢ Tiempo LLM: 607ms
‚Ä¢ Tiempo TOTAL: 924ms
‚Ä¢ RTF Pipeline: 0.37x
```

**Estado**: ‚úÖ **BUENO** (<1s)

**Flujo**:
```
Audio (2.5s) ‚Üí ASR (317ms) ‚Üí LLM (607ms) ‚Üí Respuesta
Total: 924ms para procesar y responder
```

## üìà Comparaci√≥n: Estimado vs Real

| Componente | Estimado | Real | Status |
|------------|----------|------|--------|
| LLM Latencia | 200-500ms | 294ms | ‚úÖ Dentro del rango |
| ASR RTF | 0.10-0.25x | 0.24x | ‚úÖ Dentro del rango |
| Pipeline | 300-750ms | 924ms | ‚ö†Ô∏è Ligeramente m√°s lento |

**An√°lisis**: El pipeline completo toma 924ms, un poco m√°s que el estimado superior (750ms), pero sigue siendo **excelente para tiempo real** ya que est√° por debajo de 1 segundo.

## üéØ Conclusi√≥n

### ‚úÖ Sistema Validado para Tiempo Real

El sistema puede manejar conversaciones en tiempo real con excelente rendimiento:

- **ASR**: Procesa audio 4x m√°s r√°pido que tiempo real
- **LLM**: Genera respuestas en menos de 300ms
- **Pipeline**: Responde en menos de 1 segundo

### üöÄ Optimizaciones Confirmadas

Las siguientes optimizaciones est√°n activas y funcionando:

**ASR (Whisper)**:
- ‚úÖ Modelo `tiny.en` (el m√°s r√°pido)
- ‚úÖ Cuantizaci√≥n INT8 (2-3x m√°s r√°pido que FP32)
- ‚úÖ Beam size = 1 (greedy decoding)
- ‚úÖ Sin timestamps (m√°s r√°pido)
- ‚úÖ Sin VAD interno (usa webrtcvad externo)
- ‚úÖ Threads autom√°ticos seg√∫n CPU

**LLM (Qwen)**:
- ‚úÖ Modelo 0.5B (peque√±o y r√°pido)
- ‚úÖ Cuantizaci√≥n Q4_K_M (balance velocidad/calidad)
- ‚úÖ Inferencia solo CPU (no requiere GPU)

## üìù Notas de Rendimiento

### Tiempo de Carga

**Primera ejecuci√≥n** (descarga de modelos):
- LLM: ~4.7s (descarga 491MB)
- ASR: ~1.8s (descarga ~75MB)

**Ejecuciones subsecuentes** (desde cache):
- LLM: ~0.32s
- ASR: ~0.19s
- Total: ~0.5s de carga

### Requisitos M√≠nimos vs Probado

**Requisitos m√≠nimos**:
- CPU: 4 cores
- RAM: 4GB
- Almacenamiento: 1GB libre

**Hardware de prueba**:
- CPU: AMD EPYC 7763 (4 cores utilizados)
- RAM: 16GB (uso real ~2GB)
- Almacenamiento: <1GB (modelos en cache)

### Comparaci√≥n de Modelos

| Modelo ASR | Tama√±o | RTF Estimado | Uso Recomendado |
|------------|--------|--------------|-----------------|
| **tiny.en** | 75MB | 0.10-0.25x | ‚úÖ **Recomendado** para tiempo real |
| base.en | 150MB | 0.40-0.60x | ‚ö†Ô∏è M√°s lento, mejor precisi√≥n |
| small.en | 500MB | 0.80-1.20x | ‚ùå Muy lento para tiempo real |

## üîß C√≥mo Mejorar el Rendimiento

Si necesitas a√∫n m√°s velocidad:

### Opci√≥n 1: GPU (5-10x m√°s r√°pido)
```python
# Configurar para usar GPU NVIDIA
asr_compute_type: "float16"
device: "cuda"
```
**Resultado esperado**:
- ASR RTF: 0.24x ‚Üí 0.02-0.05x
- LLM: 294ms ‚Üí 50-100ms

### Opci√≥n 2: Streaming M√°s Agresivo
```json
{
  "partial_every_ms": 500
}
```
Reduce de 800ms a 500ms para respuesta m√°s r√°pida (usa m√°s CPU).

### ‚ùå No Recomendado

- Cambiar a `base.en` o modelos m√°s grandes (m√°s lento)
- Aumentar `beam_size` (m√°s lento sin mejora perceptible)
- Activar `vad_filter=True` (redundante con VAD externo)

## üìä M√©tricas Clave

**RTF (Real-Time Factor)**: Tiempo de procesamiento / Duraci√≥n del audio
- RTF < 1.0 = M√°s r√°pido que tiempo real ‚úÖ
- RTF = 1.0 = Igual a tiempo real
- RTF > 1.0 = M√°s lento que tiempo real ‚ùå

**Nuestro RTF**: 0.24x (ASR) y 0.37x (Pipeline)
- ‚úÖ **4.2x m√°s r√°pido** que tiempo real para ASR
- ‚úÖ **2.7x m√°s r√°pido** que tiempo real para el pipeline completo

---

*√öltima actualizaci√≥n*: 2026-02-03  
*Ambiente de prueba*: GitHub Actions Runner (Linux, AMD EPYC)  
*Status*: ‚úÖ **Aprobado para producci√≥n**
