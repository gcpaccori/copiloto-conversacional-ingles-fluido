# Copiloto Conversacional en InglÃ©s Fluido

Sistema de conversaciÃ³n en tiempo real con IA para practicar inglÃ©s, optimizado para CPU.

## ğŸ¯ CaracterÃ­sticas

- **ASR en Tiempo Real**: TranscripciÃ³n de audio usando Whisper (faster-whisper)
- **LLM Local**: Sugerencias conversacionales con Qwen 0.5B
- **Optimizado para CPU**: No requiere GPU, funciona en hardware comÃºn
- **Doble Captura**: MicrÃ³fono (tu voz) + Loopback (audio del sistema)
- **Overlay Transparente**: Interfaz no intrusiva con sugerencias en pantalla

## ğŸš€ InstalaciÃ³n RÃ¡pida

### Requisitos
- Python 3.8+
- Windows 10/11 (para captura de audio WASAPI)
- 4GB RAM mÃ­nimo, 8GB recomendado
- CPU de 4 nÃºcleos o mÃ¡s

### InstalaciÃ³n

```powershell
# Clonar repositorio
git clone https://github.com/gcpaccori/copiloto-conversacional-ingles-fluido.git
cd copiloto-conversacional-ingles-fluido

# Crear entorno virtual e instalar dependencias
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

### Modelos Requeridos

Los modelos se descargan automÃ¡ticamente desde HuggingFace la primera vez:

**ASR (Whisper tiny.en)**
- Se descarga automÃ¡ticamente de `Systran/faster-whisper-tiny.en`
- TamaÃ±o: ~75MB

**LLM (Qwen 0.5B)**
- Se descarga automÃ¡ticamente de `Qwen/Qwen2.5-0.5B-Instruct-GGUF`
- Archivo: `qwen2.5-0.5b-instruct-q4_k_m.gguf`
- TamaÃ±o: ~491MB

## â–¶ï¸ Uso

```powershell
# Ejecutar la aplicaciÃ³n
python app/main.py
```

### ConfiguraciÃ³n Inicial

1. Selecciona tu **micrÃ³fono** (tu voz)
2. Selecciona **Loopback** (audio del sistema - Teams/Zoom/etc)
3. El sistema descargarÃ¡ los modelos automÃ¡ticamente
4. Â¡Listo para usar!

### Atajos de Teclado

- **F8**: Alternar click-through del overlay
- **F9**: Mostrar/ocultar overlay
- **F10**: Fijar overlay encima (topmost)

## ğŸ“Š Rendimiento

Sistema validado en CPU sin GPU. Ver [PERFORMANCE.md](PERFORMANCE.md) para resultados detallados.

**Velocidades Medidas (CPU AMD EPYC 7763, 4 cores):**
- ASR: ~316ms por transcripciÃ³n (RTF 0.24x)
- LLM: ~294ms por respuesta
- Pipeline completo: ~924ms

âœ… **Apto para conversaciones en tiempo real**

## ğŸ“ Estructura del Proyecto

```
copiloto-conversacional-ingles-fluido/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Punto de entrada
â”‚   â”œâ”€â”€ audio/               # Captura y procesamiento de audio
â”‚   â”œâ”€â”€ asr/                 # Motor de transcripciÃ³n (Whisper)
â”‚   â”œâ”€â”€ llm/                 # Motor LLM (Qwen)
â”‚   â”œâ”€â”€ coach/               # LÃ³gica de sugerencias
â”‚   â”œâ”€â”€ ui/                  # Interfaz de usuario
â”‚   â””â”€â”€ utils/               # Utilidades
â”œâ”€â”€ scripts/                 # Scripts de instalaciÃ³n
â”œâ”€â”€ config.default.json      # ConfiguraciÃ³n por defecto
â””â”€â”€ requirements.txt         # Dependencias Python
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

Edita `config.json` (se crea en primera ejecuciÃ³n) para ajustar:

```json
{
  "asr_model_size": "Systran/faster-whisper-tiny.en",
  "asr_compute_type": "int8",
  "llm_model_path": "",
  "sample_rate": 16000
}
```

## ğŸ› ï¸ Desarrollo

### Instalar dependencias de desarrollo

```bash
pip install -r requirements-optional.txt
```

### Ejecutar tests

```bash
# Verificar configuraciÃ³n del sistema
python verify_asr_config.py

# Test de descarga y rendimiento
python test_real_performance.py
```

## ğŸ“ Notas TÃ©cnicas

- **ASR**: Usa `faster-whisper` con modelo `tiny.en` + cuantizaciÃ³n INT8
- **LLM**: Usa `llama-cpp-python` con modelo Qwen Q4_K_M
- **VAD**: Usa `webrtcvad` para detecciÃ³n de voz
- **Audio**: Captura WASAPI en Windows

### Optimizaciones Implementadas

- Beam size = 1 (greedy decoding)
- Sin timestamps en transcripciÃ³n
- CuantizaciÃ³n INT8 para ASR
- CuantizaciÃ³n Q4_K_M para LLM
- Threads automÃ¡ticos segÃºn CPU

## ğŸ¤ Contribuir

Las contribuciones son bienvenidas. Por favor:
1. Haz fork del repositorio
2. Crea una rama para tu feature
3. Haz commit de tus cambios
4. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT.

## ğŸ™ CrÃ©ditos

- **Whisper**: OpenAI
- **faster-whisper**: SYSTRAN
- **Qwen**: Alibaba Cloud
- **llama-cpp-python**: Comunidad llama.cpp
