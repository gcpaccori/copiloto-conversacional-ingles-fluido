# Copiloto Conversacional en Ingl√©s Fluido

Sistema de conversaci√≥n en tiempo real con IA para practicar ingl√©s, optimizado para CPU.

## üéØ Caracter√≠sticas

- **ASR en Tiempo Real**: Transcripci√≥n de audio usando Whisper (faster-whisper)
- **LLM Local**: Sugerencias conversacionales con Qwen 0.5B
- **Optimizado para CPU**: No requiere GPU, funciona en hardware com√∫n
- **Doble Captura**: Micr√≥fono (tu voz) + Loopback (audio del sistema)
- **Overlay Transparente**: Interfaz no intrusiva con sugerencias en pantalla

## üöÄ Instalaci√≥n R√°pida

### Requisitos
- Python 3.8+
- Windows 10/11 (para captura de audio WASAPI)
- 4GB RAM m√≠nimo, 8GB recomendado
- CPU de 4 n√∫cleos o m√°s

### Instalaci√≥n

```powershell
# Clonar repositorio
git clone https://github.com/gcpaccori/copiloto-conversacional-ingles-fluido.git
cd copiloto-conversacional-ingles-fluido

# Crear entorno virtual e instalar dependencias
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

### Modelos Requeridos

Los modelos se descargan autom√°ticamente desde HuggingFace la primera vez:

**ASR (Whisper tiny.en)**
- Se descarga autom√°ticamente de `Systran/faster-whisper-tiny.en`
- Tama√±o: ~75MB

**LLM (Qwen 0.5B)**
- Se descarga autom√°ticamente de `Qwen/Qwen2.5-0.5B-Instruct-GGUF`
- Archivo: `qwen2.5-0.5b-instruct-q4_k_m.gguf`
- Tama√±o: ~491MB

## ‚ñ∂Ô∏è Uso

```powershell
# Ejecutar la aplicaci√≥n
python app/main.py
```

### Configuraci√≥n Inicial

1. Selecciona tu **micr√≥fono** (tu voz)
2. Selecciona **Loopback** (audio del sistema - Teams/Zoom/etc)
3. El sistema descargar√° los modelos autom√°ticamente
4. ¬°Listo para usar!

### Atajos de Teclado

- **F8**: Alternar click-through del overlay
- **F9**: Mostrar/ocultar overlay
- **F10**: Fijar overlay encima (topmost)

## üìä Rendimiento

Sistema validado en CPU sin GPU. Ver [PERFORMANCE.md](PERFORMANCE.md) para resultados detallados.

**Velocidades Medidas (CPU AMD EPYC 7763, 4 cores):**
- ASR: ~316ms por transcripci√≥n (RTF 0.24x)
- LLM: ~294ms por respuesta
- Pipeline completo: ~924ms

‚úÖ **Apto para conversaciones en tiempo real**

### üìã Caracter√≠sticas Completas

Ver [FEATURES_ES.md](FEATURES_ES.md) para documentaci√≥n completa en espa√±ol sobre:
- ‚úÖ Pruebas de rendimiento del flujo completo (audio ‚Üí transcripci√≥n ‚Üí respuesta)
- ‚úÖ Manejo de preguntas largas y complejas (hasta 15+ segundos)
- ‚úÖ Tiempos de respuesta verificados (< 2 segundos)
- ‚úÖ Configuraci√≥n de contexto inicial personalizado (profile + goal)
- ‚úÖ Carga de documentos PDF (niveles de ingl√©s, t√©cnicas, vocabulario)
- ‚úÖ Funcionalidad completa como copiloto conversacional

## üìÅ Estructura del Proyecto

```
copiloto-conversacional-ingles-fluido/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Punto de entrada
‚îÇ   ‚îú‚îÄ‚îÄ audio/               # Captura y procesamiento de audio
‚îÇ   ‚îú‚îÄ‚îÄ asr/                 # Motor de transcripci√≥n (Whisper)
‚îÇ   ‚îú‚îÄ‚îÄ llm/                 # Motor LLM (Qwen)
‚îÇ   ‚îú‚îÄ‚îÄ coach/               # L√≥gica de sugerencias
‚îÇ   ‚îú‚îÄ‚îÄ ui/                  # Interfaz de usuario
‚îÇ   ‚îî‚îÄ‚îÄ utils/               # Utilidades
‚îú‚îÄ‚îÄ scripts/                 # Scripts de instalaci√≥n
‚îú‚îÄ‚îÄ config.default.json      # Configuraci√≥n por defecto
‚îî‚îÄ‚îÄ requirements.txt         # Dependencias Python
```

## üîß Configuraci√≥n Avanzada

Edita `config.json` (se crea en primera ejecuci√≥n) para ajustar:

```json
{
  "asr_model_size": "Systran/faster-whisper-tiny.en",
  "asr_compute_type": "int8",
  "llm_model_path": "",
  "sample_rate": 16000
}
```

## üõ†Ô∏è Desarrollo

### Instalar dependencias de desarrollo

```bash
pip install -r requirements-optional.txt
```

### Ejecutar tests

```bash
# Verificaci√≥n r√°pida (sin descargar modelos)
python test_quick_verification.py

# Test de rendimiento completo (descarga modelos autom√°ticamente)
python test_full_performance.py
```

Ver [TESTING.md](TESTING.md) para gu√≠a completa de testing.

## üìù Notas T√©cnicas

- **ASR**: Usa `faster-whisper` con modelo `tiny.en` + cuantizaci√≥n INT8
- **LLM**: Usa `llama-cpp-python` con modelo Qwen Q4_K_M
- **VAD**: Usa `webrtcvad` para detecci√≥n de voz
- **Audio**: Captura WASAPI en Windows

### Optimizaciones Implementadas

- Beam size = 1 (greedy decoding)
- Sin timestamps en transcripci√≥n
- Cuantizaci√≥n INT8 para ASR
- Cuantizaci√≥n Q4_K_M para LLM
- Threads autom√°ticos seg√∫n CPU

## ü§ù Contribuir

Las contribuciones son bienvenidas. Por favor:
1. Haz fork del repositorio
2. Crea una rama para tu feature
3. Haz commit de tus cambios
4. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo licencia MIT.

## üôè Cr√©ditos

- **Whisper**: OpenAI
- **faster-whisper**: SYSTRAN
- **Qwen**: Alibaba Cloud
- **llama-cpp-python**: Comunidad llama.cpp
